{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f209f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERADOR DE ARCHIVOS CSV FINALES PARA CONSUMIR Y GENERAR EL .TTL\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def getCoordenadas(csv_file):\n",
    "    coordenadas = set()\n",
    "    with open(csv_file, \"r\", encoding=\"utf-8\") as file:\n",
    "\n",
    "        lector = csv.DictReader(file)\n",
    "\n",
    "        for fila in lector:\n",
    "            \n",
    "            lat = fila.get(\"decimalLatitude\")\n",
    "            lon = fila.get(\"decimalLongitude\")\n",
    "            especie = fila.get(\"scientificName\")\n",
    "            reino = fila.get(\"kingdom\")\n",
    "            nombre_comun = fila.get(\"vernacularName\")\n",
    "\n",
    "            if lat and lon:\n",
    "                coordenadas.add((float(lat), float(lon), especie, reino, nombre_comun))\n",
    "    return coordenadas\n",
    "\n",
    "coordenadas_lp = getCoordenadas(\"csv/ocurrence_la_plata.csv\")\n",
    "coordenadas_bsas = getCoordenadas(\"csv/ocurrence_prov_bsas.csv\")\n",
    "\n",
    "coordenadas_union = coordenadas_lp.union(coordenadas_bsas) # ya esta\n",
    "\n",
    "df_especies = pd.DataFrame(coordenadas_union, columns=[\"lat\", \"long\", \"especie\", \"reino\", \"nombre_comun\"]) \n",
    "\n",
    "df_especies = pd.DataFrame(df_especies, columns=[\"lat\", \"long\", \"especie\", \"reino\", \"nombre_comun\"])\n",
    "\n",
    "coordenadas_personalizado = getCoordenadas(\"csv/ocurrence_personalizado.csv\")\n",
    "\n",
    "df_personalizado = pd.DataFrame(coordenadas_personalizado, columns=[\"lat\", \"long\", \"especie\", \"reino\", \"nombre_comun\"])\n",
    "\n",
    "#aca uno el dataframe de especies(coordenadas_union) y el dataframe personalizado\n",
    "df_union = pd.concat([df_especies, df_personalizado], ignore_index=True).drop_duplicates()\n",
    "\n",
    "df_union.to_csv(\"csv/datos_especies_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4c836",
   "metadata": {},
   "source": [
    "La siguiente celda contiene el código para cargar el .ttl que tendra información de cada inmueble visto de la ontologia del OVS, con información acerca de \n",
    "especies vistas en un radio de 500 metros, también cuenta con la localización de cada observación individual.\n",
    "Se puede omitir esta celda que tarda aprox. 28 minutos en ejecutarse, porque el .ttl ya se encuentra en la carpeta \"grafos\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b38b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERADOR DEL .TTL, esta celda contiene el código para poder generar el archivo RDF\n",
    "#tarda aprox. 28 minutos en generarlo\n",
    "\n",
    "import pandas as pd\n",
    "from rdflib import Graph, Literal, URIRef, Namespace\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "\n",
    "#Def de prefijos\n",
    "BIO_NS = Namespace(\"http://www.semanticweb.org/barre/ontologies/2025/8/bio-ontology/\")\n",
    "OVS_NS = Namespace(\"http://www.semanticweb.org/luciana/ontologies/2024/8/inmontology\")\n",
    "DWC_NS = Namespace(\"http://rs.tdwg.org/dwc/terms/\") \n",
    "\n",
    "try: \n",
    "    df_total = pd.read_csv(\"datos_para_rdf/datos_con_conteo_total.csv\")\n",
    "    df_detalles = pd.read_csv(\"datos_para_rdf/datos_especies_detallados.csv\")\n",
    "    df_observaciones = pd.read_csv(\"csv/datos_especies_final.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}.\")\n",
    "    exit()\n",
    "\n",
    "BUFFER_RADIUS_METERS = 500\n",
    "\n",
    "g_biodiv_data = Graph()\n",
    "g_biodiv_data.bind(\"bio\", BIO_NS)\n",
    "g_biodiv_data.bind(\"io\", OVS_NS)\n",
    "g_biodiv_data.bind(\"dwc\", DWC_NS)\n",
    "g_biodiv_data.bind(\"rdfs\", RDFS)\n",
    "g_biodiv_data.bind(\"xsd\", XSD)\n",
    "\n",
    "\n",
    "#agregado de inmuebles\n",
    "print(\"Procesando inmuebles\")\n",
    "for index, row in df_total.iterrows():\n",
    "    inmueble_uri_str = str(row['URI_Inmueble'])\n",
    "    if pd.isna(inmueble_uri_str):\n",
    "        continue\n",
    "        \n",
    "    inmueble_uri = URIRef(inmueble_uri_str)\n",
    "    inmueble_uri_part = inmueble_uri_str.split('#')[-1]\n",
    "    agg_uri = BIO_NS[f\"Agg_{inmueble_uri_part}\"]\n",
    "    \n",
    "    #triples del agregado\n",
    "    g_biodiv_data.add((agg_uri, RDF.type, BIO_NS.ObservationAggregate))\n",
    "    g_biodiv_data.add((agg_uri, BIO_NS.observedAt, inmueble_uri))\n",
    "    g_biodiv_data.add((agg_uri, BIO_NS.totalObservations, Literal(row['Total_Especies_Unicas'], datatype=XSD.integer)))\n",
    "    g_biodiv_data.add((agg_uri, BIO_NS.bufferRadius, Literal(BUFFER_RADIUS_METERS, datatype=XSD.integer)))\n",
    "    \n",
    "    wkt_point = f\"POINT({row['Longitud']} {row['Latitud']})\"\n",
    "    g_biodiv_data.add((agg_uri, BIO_NS.asWKT, Literal(wkt_point, datatype=XSD.string)))\n",
    "    \n",
    "    #procesar los detalles de especies\n",
    "    detalles_inmueble = df_detalles[df_detalles['URI_Inmueble'] == inmueble_uri_str]\n",
    "    \n",
    "    for _, detalle in detalles_inmueble.iterrows():\n",
    "        especie_cientifica = detalle['especie']\n",
    "        conteo_especie = detalle['conteo_especie_en_buffer']\n",
    "        \n",
    "        if pd.isna(especie_cientifica):\n",
    "            continue\n",
    "\n",
    "        especie_uri = BIO_NS[f\"Taxon_{especie_cientifica.replace(' ', '_')}\"]\n",
    "        \n",
    "        g_biodiv_data.add((especie_uri, RDF.type, BIO_NS.Taxon))\n",
    "        \n",
    "        if pd.notna(detalle['nombre_comun']):\n",
    "            g_biodiv_data.add((especie_uri, RDFS.label, Literal(detalle['nombre_comun'], lang='es')))\n",
    "        \n",
    "        g_biodiv_data.add((agg_uri, BIO_NS.hasSpecies, especie_uri))\n",
    "        g_biodiv_data.add((especie_uri, BIO_NS.speciesCountForAggregate, Literal(conteo_especie, datatype=XSD.integer)))\n",
    "\n",
    "print(f\"Procesados {len(df_total)} inmuebles\")\n",
    "\n",
    "#procesamieno de observaciones individuales\n",
    "print(\"\\nProcesando observaciones individuales\")\n",
    "observaciones_procesadas = 0\n",
    "\n",
    "for index, row in df_observaciones.iterrows():\n",
    "    lat = row['lat']\n",
    "    lon = row['long']\n",
    "    especie_cientifica = row['especie']\n",
    "    reino = row['reino']\n",
    "    nombre_comun = row['nombre_comun']\n",
    "    \n",
    "    if pd.isna(especie_cientifica) or pd.isna(lat) or pd.isna(lon):\n",
    "        continue\n",
    "    \n",
    "    obs_uri = BIO_NS[f\"Obs_{index}\"]\n",
    "    \n",
    "    g_biodiv_data.add((obs_uri, RDF.type, BIO_NS.IndividualObservation))\n",
    "    \n",
    "    #agregar las coords.\n",
    "    wkt_obs = f\"POINT({lon} {lat})\"\n",
    "    g_biodiv_data.add((obs_uri, BIO_NS.asWKT, Literal(wkt_obs, datatype=XSD.string)))\n",
    "    \n",
    "    #vinculo con la especie\n",
    "    especie_uri = BIO_NS[f\"Taxon_{especie_cientifica.replace(' ', '_')}\"]\n",
    "    g_biodiv_data.add((obs_uri, BIO_NS.hasSpecies, especie_uri))\n",
    "    \n",
    "    g_biodiv_data.add((especie_uri, RDF.type, BIO_NS.Taxon))\n",
    "    \n",
    "    if pd.notna(reino) and str(reino).strip() != '':\n",
    "        g_biodiv_data.add((obs_uri, BIO_NS.kingdom, Literal(str(reino), datatype=XSD.string)))\n",
    "    \n",
    "    if pd.notna(nombre_comun) and str(nombre_comun).strip() != '':\n",
    "        g_biodiv_data.add((especie_uri, RDFS.label, Literal(str(nombre_comun), lang='es')))\n",
    "    \n",
    "    observaciones_procesadas += 1\n",
    "\n",
    "print(f\"Hay {observaciones_procesadas} observaciones individuales\")\n",
    "\n",
    "output_file = \"grafos/biodiv_inmuebles_la_plata_COMPLETO.ttl\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(g_biodiv_data.serialize(format=\"turtle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf7e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta es la query basica para poder generar los mapas de calor, la query trae datos de cada inmueble, con sus coordenadas y\n",
    "#la cantidad total de especies vistas en cada uno.\n",
    "import pandas as pd\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://localhost:3030/OVS-Biodiversidad/query\")\n",
    "\n",
    "sparql.setQuery(\"\"\"\n",
    "PREFIX bio: <http://www.semanticweb.org/barre/ontologies/2025/8/bio-ontology/>\n",
    "\n",
    "SELECT ?InmuebleURI ?PuntoWKT ?ConteoTotal \n",
    "WHERE {\n",
    "  ?Agregado bio:observedAt ?InmuebleURI .\n",
    "\n",
    "  ?Agregado bio:asWKT ?PuntoWKT .\n",
    "\n",
    "  ?Agregado bio:totalObservations ?ConteoTotal .\n",
    "  \n",
    "}\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "try:\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    data = []\n",
    "    #results['results']['bindings'] contiene la lista de todas las filas devueltas\n",
    "    for result in results['results']['bindings']:\n",
    "        data.append({\n",
    "            'URI_Inmueble': result['InmuebleURI']['value'],\n",
    "            'WKT_Geometria': result['PuntoWKT']['value'],\n",
    "            'Total_Especies_Unicas': float(result['ConteoTotal']['value'])\n",
    "        })\n",
    "\n",
    "    df_sparql = pd.DataFrame(data)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total de registros obtenidos: {len(df_sparql)}\")\n",
    "    display(df_sparql)\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al ejecutar la consulta SPARQL: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb9e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para guardar el dataframe en un archivo CSV\n",
    "df_sparql.to_csv(\"mapa_calor_sparql/datos_basicos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea787a",
   "metadata": {},
   "source": [
    "### Idea central\n",
    "\n",
    "La idea de la combinación de los datasets fue poder mostrar el impacto que tienen los inmuebles sobre la biodiversidad en el partido de La Plata. \n",
    "A los datos obtenidos del OVS se les hizo un análisis geoespacial con la API de Google Maps para poder obtener las coordenadas (no venían incluidas en el OVS). Luego se pasaron esos datos a un CSV para facilitar la extracción y análisis de datos, y se combinaron esos datos con un archivo .CSV que contenía información de especies vistas en el partido de La Plata, este CSV lo extraje desde INaturalist. Para cada inmueble se le asigno un radio de 500 metros para el análisis de las especies cercanas a este y se guardo en un csv la información relacionando a cada inmueble con sus coordenadas y una lista con el nombre de cada especie vista. Después se paso toda esta información a un archivo .ttl, que tenía las bases del OVS, y se le sumo información relacionada a la biodiversidad, para poder hacer consultas en una base de datos no relacional como SPARQL. Para finalizar muestro las consultas SPARQL necesarias para obtener datos y poder generar los mapas de calor para consumir la información visualmente y poder tener un análisis más cómodo.\n",
    "A continuación se generarán mapas con información relacionada a:\n",
    "- Mapa que muestra para cada inmueble la cantidad de especies distintas que tienen en un radio de 500 metros. A cada inmueble se le asigna un color (rojo, verde, amarillo o gris) dependiendo de la cantidad de especies cercanas.\n",
    "- Mapa de calor que muestra la distribución de las especies.\n",
    "- Mapa de claor que muestra la distribución de los inmuebles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4bb02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#este script genera el mapa de calor que define para cada inmueble un color\n",
    "#dependiendo de la cantidad de especies únicas vistas en el mismo\n",
    "import folium\n",
    "import webbrowser\n",
    "from shapely import wkt\n",
    "import pandas as pd\n",
    "\n",
    "df_sparql = pd.read_csv(\"mapa_calor_sparql/datos_basicos.csv\")\n",
    "\n",
    "df_sparql['geometry'] = df_sparql['WKT_Geometria'].apply(wkt.loads)\n",
    "\n",
    "mapa_impacto_inmuebles = folium.Map(location=[-34.921, -57.954], zoom_start=12) #coordenadas de La Plata\n",
    "\n",
    "def get_color(conteo):\n",
    "    if conteo == 0:\n",
    "        return 'grey' #biodiversidad nula\n",
    "    elif conteo < 5:\n",
    "        return 'green' #biodiversidad baja\n",
    "    elif conteo < 10:\n",
    "        return 'orange' #biodiversidad media\n",
    "    else:\n",
    "        return 'red' #biodiversidad alta\n",
    "    \n",
    "for index, row in df_sparql.iterrows():\n",
    "    geometria = row['geometry']\n",
    "    conteo = row['Total_Especies_Unicas']\n",
    "    uri = row['URI_Inmueble']\n",
    "\n",
    "    popup_text = f\"\"\"\n",
    "    <b>Inmueble URI:</b> {uri}<br>\n",
    "    <b>Especies únicas:</b> {int(conteo)}\n",
    "    \"\"\"\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=(geometria.y, geometria.x),\n",
    "        radius=5,\n",
    "        color=get_color(conteo),\n",
    "        fill_opacity=0.6,\n",
    "        popup=folium.Popup(popup_text)\n",
    "    ).add_to(mapa_impacto_inmuebles)\n",
    "\n",
    "mapa_html = \"mapa_calor_sparql/mapa_impacto_inmuebles.html\"\n",
    "mapa_impacto_inmuebles.save(mapa_html)\n",
    "webbrowser.open(mapa_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c817bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta celda tiene el script para generar una consulta SPARQL\n",
    "#que obtiene info. solamente de los inmuebles, para posteriormente generar el mapa de calor\n",
    "import pandas as pd\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://localhost:3030/OVS-Biodiversidad/query\")\n",
    "\n",
    "sparql.setQuery(\"\"\"\n",
    "PREFIX bio: <http://www.semanticweb.org/barre/ontologies/2025/8/bio-ontology/>\n",
    "\n",
    "SELECT ?InmuebleURI ?PuntoWKT \n",
    "WHERE {\n",
    "  ?Agregado bio:observedAt ?InmuebleURI .\n",
    "\n",
    "  ?Agregado bio:asWKT ?PuntoWKT .\n",
    "}\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "try:\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    data = []\n",
    "    for result in results['results']['bindings']:\n",
    "        data.append({\n",
    "            'URI_Inmueble': result['InmuebleURI']['value'],\n",
    "            'WKT_Geometria': result['PuntoWKT']['value']\n",
    "        })\n",
    "\n",
    "    df_sparql_inmuebles = pd.DataFrame(data)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total de registros obtenidos: {len(df_sparql_inmuebles)}\")\n",
    "    display(df_sparql_inmuebles)\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    df_sparql_inmuebles.to_csv(\"mapa_calor_sparql/datos_inmuebles.csv\", index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al ejecutar la consulta SPARQL: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f71994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapas de calor, de inmuebles\n",
    "import folium\n",
    "import webbrowser\n",
    "from folium.plugins import HeatMap\n",
    "from shapely import wkt\n",
    "import pandas as pd\n",
    "\n",
    "df_sparql_inmuebles = pd.read_csv(\"mapa_calor_sparql/datos_inmuebles.csv\")\n",
    "\n",
    "df_sparql_inmuebles['geometry'] = df_sparql_inmuebles['WKT_Geometria'].apply(wkt.loads)\n",
    "df_sparql_inmuebles['coords'] = df_sparql_inmuebles['geometry'].apply(lambda g: [g.y, g.x])\n",
    "\n",
    "#mapa de calor de inmuebles\n",
    "mapa_calor_inmuebles = folium.Map(location=[-34.921, -57.954], zoom_start=12)\n",
    "HeatMap(df_sparql_inmuebles['coords'].tolist()).add_to(mapa_calor_inmuebles)\n",
    "\n",
    "mapa_html_inmuebles = \"mapa_calor_sparql/mapa_calor_inmuebles.html\"\n",
    "\n",
    "mapa_calor_inmuebles.save(mapa_html_inmuebles)\n",
    "webbrowser.open(mapa_html_inmuebles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d371e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta celda contiene el script para generar un mapa de calor a partir de la información de la cantidad de especies vistas en distintos puntos geográficos\n",
    "#permitiendo generar un mapa de calor para ver la distribución y densidad de observaciones de especies\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://localhost:3030/OVS-Biodiversidad/query\")\n",
    "\n",
    "sparql.setQuery(\"\"\"\n",
    "PREFIX bio: <http://www.semanticweb.org/barre/ontologies/2025/8/bio-ontology/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?obsURI ?coordenadasWKT ?especieURI ?nombreEspecie ?reino\n",
    "WHERE {\n",
    "  ?obsURI a bio:IndividualObservation ;\n",
    "          bio:asWKT ?coordenadasWKT ;\n",
    "          bio:hasSpecies ?especieURI .\n",
    "  OPTIONAL { ?especieURI rdfs:label ?nombreEspecie . }\n",
    "  OPTIONAL { ?obsURI bio:kingdom ?reino . }\n",
    "}\n",
    "ORDER BY ?especieURI\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "try:\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    data = []\n",
    "    for result in results['results']['bindings']:\n",
    "        data.append({\n",
    "            'Observacion_URI': result['obsURI']['value'],\n",
    "            'WKT_Geometria': result['coordenadasWKT']['value'],\n",
    "            'Especie_URI': result['especieURI']['value'],\n",
    "            'Nombre_Comun': result.get('nombreEspecie', {}).get('value', 'N/A'),\n",
    "            'Reino': result.get('reino', {}).get('value', 'N/A')\n",
    "        })\n",
    "\n",
    "    df_sparql_especies = pd.DataFrame(data)\n",
    "    \n",
    "    display(df_sparql_especies.head(10))\n",
    "    \n",
    "    df_sparql_especies.to_csv(\"mapa_calor_sparql/datos_especies_individuales.csv\", index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al ejecutar la consulta SPARQL: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df9426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapa calor de observaciones de especies\n",
    "import folium\n",
    "import webbrowser\n",
    "from folium.plugins import HeatMap\n",
    "from shapely import wkt\n",
    "import pandas as pd\n",
    "\n",
    "df_sparql_especies = pd.read_csv(\"mapa_calor_sparql/datos_especies_individuales.csv\")\n",
    "\n",
    "df_sparql_especies['geometry'] = df_sparql_especies['WKT_Geometria'].apply(wkt.loads)\n",
    "df_sparql_especies['coords'] = df_sparql_especies['geometry'].apply(lambda g: [g.y, g.x])\n",
    "\n",
    "#Mapa calor de especies\n",
    "mapa_calor_especies = folium.Map(location=[-34.921, -57.954], zoom_start=12)\n",
    "HeatMap(df_sparql_especies['coords'].tolist()).add_to(mapa_calor_especies)\n",
    "\n",
    "mapa_html_especies = \"mapa_calor_sparql/mapa_calor_especies.html\"\n",
    "\n",
    "mapa_calor_especies.save(mapa_html_especies)\n",
    "webbrowser.open(mapa_html_especies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
